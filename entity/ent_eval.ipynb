{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from string import punctuation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:45:21.472539Z",
     "start_time": "2024-01-30T06:45:21.462562800Z"
    }
   },
   "id": "9c6a30cc18ad91e8"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:45:35.885314100Z",
     "start_time": "2024-01-30T06:45:25.640286500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4826/4826 [00:10<00:00, 474.47it/s]\n"
     ]
    }
   ],
   "source": [
    "exists_results = os.listdir('GPT4_results/raw')\n",
    "\n",
    "save_dic = {}\n",
    "for idx, md5 in tqdm(enumerate(exists_results), total=len(exists_results)):\n",
    "    with open('GPT4_results/raw/' + md5, 'r', encoding='utf-8') as fraw:\n",
    "        rsp = fraw.read()\n",
    "        rsp = rsp.strip(' |\\n' + punctuation)\n",
    "        \n",
    "        entities = rsp.split('||')\n",
    "        \n",
    "        l = []\n",
    "        for entity in entities:\n",
    "            l.append(entity.strip())\n",
    "        save_dic[md5] = l\n",
    "\n",
    "json.dump(save_dic, open('GPT4_results.json','w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4527/4527 [00:09<00:00, 471.21it/s]\n"
     ]
    }
   ],
   "source": [
    "exists_results = os.listdir('Gemini_results/raw')\n",
    "\n",
    "save_dic = {}\n",
    "for idx, md5 in tqdm(enumerate(exists_results), total=len(exists_results)):\n",
    "    with open('Gemini_results/raw/' + md5, 'r', encoding='utf-8') as fraw:\n",
    "        rsp = fraw.read()\n",
    "        rsp = rsp.strip(' |\\n' + punctuation)\n",
    "        \n",
    "        entities = rsp.split('||')\n",
    "        \n",
    "        l = []\n",
    "        for entity in entities:\n",
    "            l.append(entity.strip())\n",
    "        save_dic[md5] = l\n",
    "\n",
    "json.dump(save_dic, open('Gemini_results.json','w'), indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:45:47.907344800Z",
     "start_time": "2024-01-30T06:45:38.246832900Z"
    }
   },
   "id": "6bf1224ee2eee3cf"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3486/3486 [00:00<00:00, 16908.31it/s]\n"
     ]
    }
   ],
   "source": [
    "exists_results = os.listdir('GPT4Turbo_results/raw')\n",
    "\n",
    "save_dic = {}\n",
    "for idx, md5 in tqdm(enumerate(exists_results), total=len(exists_results)):\n",
    "    with open('GPT4Turbo_results/raw/' + md5, 'r', encoding='utf-8') as fraw:\n",
    "        rsp = fraw.read()\n",
    "        rsp = rsp.strip(' |\\n' + punctuation)\n",
    "        \n",
    "        entities = rsp.split('||')\n",
    "        \n",
    "        l = []\n",
    "        for entity in entities:\n",
    "            l.append(entity.strip())\n",
    "        save_dic[md5] = l\n",
    "\n",
    "json.dump(save_dic, open('GPT4t_results.json','w'), indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:54:22.930966600Z",
     "start_time": "2024-01-30T06:54:22.661229800Z"
    }
   },
   "id": "d43824bfe829e015"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "Gemini_results = json.load(open('Gemini_results.json', 'r'))\n",
    "GPT4_results = json.load(open('GPT4_results.json', 'r'))\n",
    "GPT4t_results = json.load(open('GPT4t_results.json', 'r'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:54:29.315965500Z",
     "start_time": "2024-01-30T06:54:29.272012500Z"
    }
   },
   "id": "bd0044b3a50eb3fd"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "for key, value in GPT4_results.items():\n",
    "    for v in value:\n",
    "        ground_truth.append(v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:28:02.322103800Z",
     "start_time": "2024-01-30T03:28:02.311367100Z"
    }
   },
   "id": "a7bdbae9c795405d"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "Gemini = []\n",
    "for key, value in Gemini_results.items():\n",
    "    for v in value:\n",
    "        Gemini.append(v)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T03:28:02.614413100Z",
     "start_time": "2024-01-30T03:28:02.612136500Z"
    }
   },
   "id": "6db150fa47c918e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "576cd7df6abdb3ea"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "macro_sum = {\"precision\": 0, \"recall\": 0, \"f1\": 0}\n",
    "micro_total = {\"true_positives\": 0, \"predicted\": 0, \"actual\": 0}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:55:35.892086100Z",
     "start_time": "2024-01-30T06:55:35.886051200Z"
    }
   },
   "id": "2117c26af5c4eb1a"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def calculate_precision_recall_f1(pred: List[Dict], gold: List[Dict]) -> Dict:\n",
    "    true_positives = len([event for event in pred if event in gold])\n",
    "    precision = true_positives / len(pred) if pred else 0\n",
    "    recall = true_positives / len(gold) if gold else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:55:34.704726100Z",
     "start_time": "2024-01-30T06:55:34.698400100Z"
    }
   },
   "id": "c7484590e3a56d48"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "for key, value in Gemini_results.items():\n",
    "    pred = value\n",
    "    gold = GPT4_results[key]\n",
    "\n",
    "    # Calculate for each truck\n",
    "    scores = calculate_precision_recall_f1(pred, gold)\n",
    "    for key in macro_sum:\n",
    "        macro_sum[key] += scores[key]\n",
    "\n",
    "    # Micro averages totals\n",
    "    micro_total[\"true_positives\"] += len([event for event in pred if event in gold])\n",
    "    micro_total[\"predicted\"] += len(pred)\n",
    "    micro_total[\"actual\"] += len(gold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:55:37.794735Z",
     "start_time": "2024-01-30T06:55:37.767197Z"
    }
   },
   "id": "5d38ff2c8ed0349c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_average': {'precision': 0.7294426307633526, 'recall': 0.5243439856440241, 'f1': 0.5986735429580398}, 'micro_average': {'precision': 0.7362313979019273, 'recall': 0.5125415308841169, 'f1': 0.604351934714721}}\n"
     ]
    }
   ],
   "source": [
    "num_docs = len(Gemini_results)\n",
    "macro_avg = {key: value / num_docs for key, value in macro_sum.items() if num_docs > 0}\n",
    "micro_precision = micro_total[\"true_positives\"] / micro_total[\"predicted\"] if micro_total[\"predicted\"] else 0\n",
    "micro_recall = micro_total[\"true_positives\"] / micro_total[\"actual\"] if micro_total[\"actual\"] else 0\n",
    "micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (\n",
    "        micro_precision + micro_recall) else 0\n",
    "micro_avg = {\"precision\": micro_precision, \"recall\": micro_recall, \"f1\": micro_f1}\n",
    "\n",
    "print({\"macro_average\": macro_avg, \"micro_average\": micro_avg})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:55:38.156778300Z",
     "start_time": "2024-01-30T06:55:38.130375200Z"
    }
   },
   "id": "7fc952147727a6a2"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "macro_sum = {\"precision\": 0, \"recall\": 0, \"f1\": 0}\n",
    "micro_total = {\"true_positives\": 0, \"predicted\": 0, \"actual\": 0}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:57:15.509594300Z",
     "start_time": "2024-01-30T06:57:15.505082300Z"
    }
   },
   "id": "9d8d4f80bdd23b49"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "for key, value in GPT4t_results.items():\n",
    "    pred = value\n",
    "    gold = GPT4_results[key]\n",
    "\n",
    "    # Calculate for each truck\n",
    "    scores = calculate_precision_recall_f1(pred, gold)\n",
    "    for key in macro_sum:\n",
    "        macro_sum[key] += scores[key]\n",
    "\n",
    "    # Micro averages totals\n",
    "    micro_total[\"true_positives\"] += len([event for event in pred if event in gold])\n",
    "    micro_total[\"predicted\"] += len(pred)\n",
    "    micro_total[\"actual\"] += len(gold)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:57:15.842523Z",
     "start_time": "2024-01-30T06:57:15.813499Z"
    }
   },
   "id": "365ee9a99382a2d"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'macro_average': {'precision': 0.7928396045414225, 'recall': 0.6294179771810295, 'f1': 0.6948323781821505}, 'micro_average': {'precision': 0.7890355469353427, 'recall': 0.6145228992326819, 'f1': 0.6909301329405487}}\n"
     ]
    }
   ],
   "source": [
    "num_docs = len(GPT4t_results)\n",
    "macro_avg = {key: value / num_docs for key, value in macro_sum.items() if num_docs > 0}\n",
    "micro_precision = micro_total[\"true_positives\"] / micro_total[\"predicted\"] if micro_total[\"predicted\"] else 0\n",
    "micro_recall = micro_total[\"true_positives\"] / micro_total[\"actual\"] if micro_total[\"actual\"] else 0\n",
    "micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall) if (\n",
    "        micro_precision + micro_recall) else 0\n",
    "micro_avg = {\"precision\": micro_precision, \"recall\": micro_recall, \"f1\": micro_f1}\n",
    "\n",
    "print({\"macro_average\": macro_avg, \"micro_average\": micro_avg})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-30T06:57:16.106853800Z",
     "start_time": "2024-01-30T06:57:16.098206500Z"
    }
   },
   "id": "f359b9b02cc0cb78"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "68e027e65641f8f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
